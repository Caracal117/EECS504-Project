{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import fnmatch\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(gt, pred):\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    d1 = (thresh < 1.25).mean()\n",
    "    d2 = (thresh < 1.25 ** 2).mean()\n",
    "    d3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = (gt - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "    err = np.abs(np.log10(pred) - np.log10(gt))\n",
    "    log10 = np.mean(err)\n",
    "\n",
    "    return  log10, abs_rel, rmse, rmse_log, d1, d2, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(preds,gts):\n",
    "\n",
    "    num_samples = len(preds)\n",
    "\n",
    "    log10 = np.zeros(num_samples, np.float32)\n",
    "    rms = np.zeros(num_samples, np.float32)\n",
    "    log_rms = np.zeros(num_samples, np.float32)\n",
    "    abs_rel = np.zeros(num_samples, np.float32)\n",
    "    d1 = np.zeros(num_samples, np.float32)\n",
    "    d2 = np.zeros(num_samples, np.float32)\n",
    "    d3 = np.zeros(num_samples, np.float32)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "\n",
    "        gt= gts[i]\n",
    "        pred = preds[i]\n",
    "\n",
    "        min_depth_eval = 1e-8\n",
    "        max_depth_eval = 255\n",
    "        pred[pred < min_depth_eval] = 1e-3\n",
    "        pred[pred > max_depth_eval] = max_depth_eval\n",
    "        gt[gt < min_depth_eval] = 1e-3\n",
    "        gt[gt > max_depth_eval] = max_depth_eval\n",
    "\n",
    "\n",
    "        log10[i], abs_rel[i], rms[i], log_rms[i], d1[i], d2[i], d3[i] = compute_errors(gt, pred)\n",
    "\n",
    "    print(\"{:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}\".format(\n",
    "        'd1', 'd2', 'd3', 'AbsRel',  'RMSE', 'RMSElog',  'log10'))\n",
    "    print(\"{:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}\".format(\n",
    "        d1.mean(), d2.mean(), d3.mean(),\n",
    "        abs_rel.mean(), rms.mean(), log_rms.mean(), log10.mean()))\n",
    "\n",
    "    return log10, abs_rel, rms, log_rms, d1, d2, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    gts = []\n",
    "    preds = []\n",
    "    pred_path = 'output/depths/'\n",
    "    gt_path = 'gt/depths/'\n",
    "    # Use glob to get a list of file paths for all JPG files in the folder\n",
    "    pred_files = glob.glob(pred_path + '*.jpg')\n",
    "    for file_path in pred_files:\n",
    "        pred = cv2.imread(file_path, -1)\n",
    "        pred = (255- pred) / 256.0\n",
    "        preds.append(pred)\n",
    "\n",
    "    print('Raw jpg files reading done')\n",
    "    print('Evaluating {} files'.format(len(preds)))\n",
    "\n",
    "    gt_files = glob.glob(gt_path + '*.jpg')\n",
    "    for file_path in gt_files:\n",
    "        gt = cv2.imread(file_path, -1)\n",
    "        gt = gt.mean(axis = 2)/ 256\n",
    "        gts.append(gt)\n",
    "    print('GT files reading done')\n",
    "    print('Evaluating {} gt files'.format(len(gts)))\n",
    "\n",
    "    print('Computing errors')\n",
    "    eval(preds,gts)\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw jpg files reading done\n",
      "Evaluating 101 files\n",
      "GT files reading done\n",
      "Evaluating 101 gt files\n",
      "Computing errors\n",
      "     d1,      d2,      d3,  AbsRel,    RMSE, RMSElog,   log10\n",
      "  0.637,   0.814,   0.884,   0.391,   0.119,   0.519,   0.136\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 255 - cv2.imread('121.jpg',-1)\n",
    "pred = pred /256\n",
    "gt = cv2.imread('121_gt.jpg',-1)\n",
    "gt = gt.mean(axis = 2)/ 256\n",
    "\n",
    "min_depth_eval = 1e-8\n",
    "max_depth_eval = 255\n",
    "pred[pred < min_depth_eval] = 1e-3\n",
    "pred[pred > max_depth_eval] = max_depth_eval\n",
    "gt[gt < min_depth_eval] = 1e-3\n",
    "gt[gt > max_depth_eval] = max_depth_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('pred',pred)\n",
    "# cv2.imshow('gt',gt)\n",
    "# cv2.waitKey(0) \n",
    "# # closing all open windows \n",
    "# cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
